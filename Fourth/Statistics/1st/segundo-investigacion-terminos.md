# Investigación de términos II

## ¿Qué son las predicciones y las inferencias?
## Predicciones

Predecir es señalar lo que puede ocurrir o suceder según una situación o acontecimiento dado.

#### Ejemplo
Si un compañero dice: “Me siento mal, me duele el estómago”.

Probablemente, se podría pensar: “Está enfermo tendrá que ir al doctor”.

Aquí se está anticipando lo que podría suceder según lo señalado por el compañero.

En la lectura, las predicciones nacen de las preguntas que el lector realiza respecto al texto leído, para anticipar lo que sucederá. Comprobar que estas predicciones son correctas, respaldan tu comprensión del texto.

Así, cuando uno piensa lo que podría suceder después de un hecho, se está prediciendo.

Lo mismo ocurre con un texto. Cuando leemos dos o tres oraciones ya podemos señalar algunas cosas que sucederán.

Veamos un ejemplo con la fábula: “Los conejos porfiados”

Había una vez un conejo que corría velozmente seguido de dos perros. De su madriguera salió rápidamente un compañero del conejo y le preguntó:…

¿Qué preguntas se pueden plantear para predecir lo que sucederá?

Formulemos algunas:

– ¿Qué le preguntó el compañero al conejo?
– ¿Qué sucederá con el conejo que está siendo perseguido?
– ¿Qué sucederá con el conejo que salió de su madriguera?

Las respuestas a estas preguntas serán tus predicciones.

Para predecir entonces, se realizan conjeturas a partir de la información que te entrega un texto. Dicha información se considera como “pistas” que ayudan a suponer lo que viene.

Estas pistas pueden ser: El título del texto, las ilustraciones, las estructura, información entregada, detalles, etc.

La predicción te ayuda a unir aquella información que ya manejas con lo que estás leyendo, por esto es tan importante que las realices cada vez que te enfrentas a un texto.

### Inferencias

Inferir es entender algo de un texto que no está literalmente escrito, sino que se deduce de la información entregada y basándonos en nuestros conocimientos previos sobre el tema. Para esto, es muy importante comprender muy bien la información entregada por el texto, a partir de la cual podrás sacar tus propias conclusiones.

#### Ejemplo

“Nicolás no paraba de estudiar a pesar del cansancio del día. Tendría la prueba mañana y para él era muy importante pasar a la Enseñanza Media. Los números no eran para él un tema muy complejo, pero la prueba consideraba lo visto durante todo el año”.

¿Qué se puede inferir del texto?

– Que es tarde y a pesar del cansancio, Nicolás sigue estudiando.

– Que Nicolás estaba en octavo ya que señala que para él era importante aprobar para pasar a la Enseñanza Media.

– Que Nicolás tiene entre 12 y 14 años, ya que va en octavo.

– Que Nicolás tiene al otro día una prueba de matemática, porque habla de los números.

Todas estas deducciones se pueden obtener del texto, a pesar de que no están literalmente escritas, pero se infieren a partir de dicha información y de los conocimientos que tenemos nosotros.

Inferir, entonces, es una actividad mental importante de la comprensión lectora, ya que logra que unas lo que te están entregando con lo que tú sabes.


## Varianza
En teoría de probabilidad, la varianza o variancia (que suele representarse como σ 2 {\displaystyle \sigma ^{2}} \sigma^2) de una variable aleatoria es una medida de dispersión definida como la esperanza del cuadrado de la desviación de dicha variable respecto a su media. O en pocas palabras, es la media de los residuos al cuadrado.

Su unidad de medida corresponde al cuadrado de la unidad de medida de la variable: por ejemplo, si la variable mide una distancia en metros, la varianza se expresa en metros al cuadrado. La varianza tiene como valor mínimo 0. La desviación estándar (raíz cuadrada de la varianza) es una medida de dispersión alternativa, expresada en las mismas unidades que los datos de la variable objeto de estudio.

Hay que tener en cuenta que la varianza puede verse muy influida por los valores atípicos y no se aconseja su uso cuando las distribuciones de las variables aleatorias tienen colas pesadas. En tales casos se recomienda el uso de otras medidas de dispersión más robustas.

## Serie temporal
Una serie temporal o cronológica es una secuencia de datos, observaciones o valores, medidos en determinados momentos y ordenados cronológicamente. Los datos pueden estar espaciados a intervalos iguales (como la temperatura en un observatorio meteorológico en días sucesivos al mediodía) o desiguales (como el peso de una persona en sucesivas mediciones en el consultorio médico, la farmacia, etc.). Para el análisis de las series temporales se usan métodos que ayudan a interpretarlas y que permiten extraer información representativa sobre las relaciones subyacentes entre los datos de la serie o de diversas series y que permiten en diferente medida y con distinta confianza extrapolar o interpolar los datos y así predecir el comportamiento de la serie en momentos no observados, sean en el futuro (extrapolación pronóstica), en el pasado (extrapolación retrógrada) o en momentos intermedios (interpolación).

https://es.wikipedia.org/wiki/Serie_temporal#Introducci%C3%B3n

## Mineria de datos
La minería de datos o exploración de datos (es la etapa de análisis de "Knowledge Discovery in Databases" o KDD) es un campo de la estadística y las ciencias de la computación referido al proceso que intenta descubrir patrones en grandes volúmenes de conjuntos de datos.1​ Utiliza los métodos de la inteligencia artificial, aprendizaje automático, estadística y sistemas de bases de datos. El objetivo general del proceso de minería de datos consiste en extraer información de un conjunto de datos y transformarla en una estructura comprensible para su uso posterior. Además de la etapa de análisis en bruto, supone aspectos de gestión de datos y de bases de datos, de procesamiento de datos, del modelo y de las consideraciones de inferencia, de métricas de Intereses, de consideraciones de la Teoría de la complejidad computacional, de post-procesamiento de las estructuras descubiertas, de la visualización y de la actualización en línea.

El término es un concepto de moda, y es frecuentemente mal utilizado para referirse a cualquier forma de datos a gran escala o procesamiento de la información (recolección, extracción, almacenamiento, análisis y estadísticas), pero también se ha generalizado a cualquier tipo de sistema de apoyo informático decisión, incluyendo la inteligencia artificial, aprendizaje automático y la inteligencia empresarial. En el uso de la palabra, el término clave es el descubrimiento, comúnmente se define como "la detección de algo nuevo". Incluso el popular libro "La minería de datos: sistema de prácticas herramientas de aprendizaje y técnicas con Java" (que cubre todo el material de aprendizaje automático) originalmente iba a ser llamado simplemente "la máquina de aprendizaje práctico", y el término "minería de datos" se añadió por razones de marketing. A menudo, los términos más generales "(gran escala) el análisis de datos", o "análisis" -. o cuando se refiere a los métodos actuales, la inteligencia artificial y aprendizaje automático, son más apropiados.

La tarea de minería de datos real es el análisis automático o semi-automático de grandes cantidades de datos para extraer patrones interesantes hasta ahora desconocidos, como los grupos de registros de datos (análisis clúster), registros poco usuales (la detección de anomalías) y dependencias (minería por reglas de asociación). Esto generalmente implica el uso de técnicas de bases de datos como los índices espaciales. Estos patrones pueden entonces ser vistos como una especie de resumen de los datos de entrada, y pueden ser utilizados en el análisis adicional o, por ejemplo, en el aprendizaje automático y análisis predictivo. Por ejemplo, el paso de minería de datos podría identificar varios grupos en los datos, que luego pueden ser utilizados para obtener resultados más precisos de predicción por un sistema de soporte de decisiones. Ni la recolección de datos, preparación de datos, ni la interpretación de los resultados y la información son parte de la etapa de minería de datos, pero que pertenecen a todo el proceso KDD como pasos adicionales.

Los términos relacionados con la obtención de datos, la pesca de datos y espionaje de los datos se refieren a la utilización de métodos de minería de datos a las partes de la muestra de un conjunto de datos de población más grandes establecidas que son (o pueden ser) demasiado pequeñas para las inferencias estadísticas fiables que se hizo acerca de la validez de cualquier patrón descubierto. Estos métodos pueden, sin embargo, ser utilizados en la creación de nuevas hipótesis que se prueban contra poblaciones de datos más grandes.

### Técnicas de minería de datos
Como ya se ha comentado, las técnicas de la minería de datos provienen de la inteligencia artificial y de la estadística, dichas técnicas, no son más que algoritmos, más o menos sofisticados que se aplican sobre un conjunto de datos para obtener unos resultados.

Las técnicas más representativas son:

    Redes neuronales.- Son un paradigma de aprendizaje y procesamiento automático inspirado en la forma en que funciona el sistema nervioso de los animales. Se trata de un sistema de interconexión de neuronas en una red que colabora para producir un estímulo de salida. Algunos ejemplos de red neuronal son:
        El perceptrón.
        El perceptrón multicapa.
        Los mapas autoorganizados, también conocidos como redes de Kohonen.

    Regresión lineal.- Es la más utilizada para formar relaciones entre datos. Rápida y eficaz pero insuficiente en espacios multidimensionales donde puedan relacionarse más de 2 variables.

    Árboles de decisión.- Un árbol de decisión es un modelo de predicción utilizado en el ámbito de la inteligencia artificial y el análisis predictivo, dada una base de datos se construyen estos diagramas de construcciones lógicas, muy similares a los sistemas de predicción basados en reglas, que sirven para representar y categorizar una serie de condiciones que suceden de forma sucesiva, para la resolución de un problema. Ejemplos:
        Algoritmo ID3.
        Algoritmo C4.5.

    Modelos estadísticos.- Es una expresión simbólica en forma de igualdad o ecuación que se emplea en todos los diseños experimentales y en la regresión para indicar los diferentes factores que modifican la variable de respuesta.

    Agrupamiento o Clustering.- Es un procedimiento de agrupación de una serie de vectores según criterios habitualmente de distancia; se tratará de disponer los vectores de entrada de forma que estén más cercanos aquellos que tengan características comunes. Ejemplos:
        Algoritmo K-means.
        Algoritmo K-medoids.

    Reglas de asociación.- Se utilizan para descubrir hechos que ocurren en común dentro de un determinado conjunto de datos.

Según el objetivo del análisis de los datos, los algoritmos utilizados se clasifican en supervisados y no supervisados (Weiss y Indurkhya, 1998):

    Algoritmos supervisados (o predictivos): predicen un dato (o un conjunto de ellos) desconocido a priori, a partir de otros conocidos.
    Algoritmos no supervisados (o del descubrimiento del conocimiento): se descubren patrones y tendencias en los datos.
https://es.wikipedia.org/wiki/Miner%C3%ADa_de_datos#Ejemplos_de_uso_de_la_miner%C3%ADa_de_datos

## Poblaciones finitas

El muestreo en poblaciones finitas o encuesta por muestreo consiste en la selección de una parte de los elementos de una población estadística (U), con el objetivo de sacar conclusiones de dicha población.

## Población infinita
Poblaciones Infinitas son concebidas por la Estadística como un conjunto de individuos, objetos o situaciones, que presentan factores comunes –más allá de su naturaleza o género, pero cuyo número se encuentra calculado más allá de cien mil elementos distintos, oponiéndose entonces al concepto de Poblaciones Finitas, conformada también por individuos con rasgos comunes, pero que cuentan con un número inferior a cien mil individuos u objetos.

## Muestra
En estadística, una muestra es un subconjunto de casos o individuos de una población. En diversas aplicaciones interesa que una muestra sea una muestra representativa y para ello debe escogerse una técnica de muestra adecuada que produzca una muestra aleatoria adecuada ( se obtiene una muestra sesgada cuyo interés y utilidad es más limitado dependiendo del grado de sesgo que presente).

Como un subgrupo o subconjunto representativo de la población, extraída seleccionada por algún método de muestreo. La muestra siempre es una parte de la población. Si se tienen varias poblaciones, entonces se tendrán varias muestras. La muestra debe poseer toda la información deseada para tener la posibilidad de extraerla, esto solo se puede lograr con una buena selección de la muestra y un trabajo muy cuidadoso y de alta calidad en la recogida de datos.
